
import asyncio
import sounddevice as sd
import webrtcvad
import collections
import time
import websockets

from soul_speak.llm.run_and_speak import tts_pipeline
from soul_speak.utils.hydra_config.init import conf

# --- æ–°å¢ï¼šå…¨å±€æ‰“æ–­äº‹ä»¶ï¼Œç”¨æ¥é€šçŸ¥ TTS åœæ­¢æ’­æ”¾ ---
interrupt_event: asyncio.Event = None

WS_URL = f"ws://{conf.asr.websocket.host}:{conf.asr.websocket.port}"
SAMPLE_RATE = conf.asr.send_audio.samplerate
FRAME_DURATION_MS = conf.asr.send_audio.frame_duration
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)
VAD_MODE = 0
VAD_SILENCE_TIMEOUT = conf.asr.send_audio.vad_silence_timeout
MIN_CHAR_COUNT = 3

# --- å…¨å±€çŠ¶æ€ ---
vad = webrtcvad.Vad(VAD_MODE)
ring_buffer = collections.deque(maxlen=int(300 / FRAME_DURATION_MS))
triggered = False
speech_buffer = bytearray()
silence_start = None

current_utterance = ""
last_text_time = time.time()
processing = False
loop = None
global_ws = None

# --- å‘é€éŸ³é¢‘æ®µ ---
async def send_audio_segment(ws):
    global speech_buffer
    if speech_buffer:
        await ws.send(speech_buffer)
        speech_buffer = bytearray()
    await ws.send("$$END$$")

# --- éŸ³é¢‘å›è°ƒï¼Œæ–°å¢â€œæ‰“æ–­æ£€æµ‹â€ ---
def audio_callback(indata, frames, time_info, status):
    global triggered, ring_buffer, speech_buffer, silence_start
    global loop, global_ws, processing, interrupt_event

    pcm = indata[:, 0].tobytes()
    is_speech = vad.is_speech(pcm, SAMPLE_RATE)

    # â€”â€” å½“ TTS æ­£åœ¨æ’­æŠ¥ä¸”æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯æ—¶ï¼Œè§¦å‘æ‰“æ–­ â€”â€” 
    if processing and is_speech and interrupt_event:
        print("ğŸ”´ Detected user speech during TTS, interrupting playback")
        interrupt_event.set()

    if not triggered:
        ring_buffer.append(pcm)
        # detect start of speech
        if sum(vad.is_speech(f, SAMPLE_RATE) for f in ring_buffer) > 0.9 * ring_buffer.maxlen:
            triggered = True
            speech_buffer.extend(b"".join(ring_buffer))
            ring_buffer.clear()
    else:
        speech_buffer.extend(pcm)
        if not is_speech:
            if silence_start is None:
                silence_start = time.time()
            elif time.time() - silence_start > VAD_SILENCE_TIMEOUT:
                # è§¦å‘å‘é€
                if loop and global_ws:
                    asyncio.run_coroutine_threadsafe(
                        send_audio_segment(global_ws), loop)
                triggered = False
                silence_start = None
        else:
            silence_start = None

# --- ç”¨æˆ·è¯è¯­æ£€æµ‹ & TTS è°ƒç”¨ï¼Œå¤ç”¨ï¼é‡ç½® interrupt_event ---
async def utterance_detector():
    global current_utterance, last_text_time, processing, interrupt_event
    while True:
        await asyncio.sleep(0.5)
        if (current_utterance.strip()
            and time.time() - last_text_time > VAD_SILENCE_TIMEOUT
            and not processing
            and len(current_utterance.strip()) >= MIN_CHAR_COUNT):

            processing = True
            text = current_utterance.strip()
            current_utterance = ""
            print(f"ğŸ“£ ç”¨æˆ·è¯è¯­å®Œæˆ: {text}")

            # â€”â€” å¦‚æœå·²æœ‰æœªç»“æŸçš„ TTSï¼Œå°±å…ˆæ‰“æ–­å¹¶åˆ›å»ºæ–°äº‹ä»¶ â€”â€” 
            if interrupt_event:
                interrupt_event.set()
            interrupt_event = asyncio.Event()

            try:
                await tts_pipeline(
                    # ä¼ å…¥æ–°çš„ interrupt_eventï¼ŒTTS æµç¨‹ä¸­ä¼šæ£€æµ‹å¹¶ä¸­æ–­
                    "Please analyze and respond: " + text,
                    interrupt_event=interrupt_event
                )
            except Exception as e:
                print(f"â— TTS å¤±è´¥: {e}")

            processing = False

# --- ä¸»æµç¨‹ ---
async def main():
    global loop, global_ws, current_utterance, last_text_time, processing

    loop = asyncio.get_running_loop()
    print(f"è¿æ¥ ASR æœåŠ¡: {WS_URL}")
    async with websockets.connect(WS_URL) as ws:
        global_ws = ws

        # å¯åŠ¨å½•éŸ³
        stream = sd.InputStream(
            callback=audio_callback,
            channels=1,
            samplerate=SAMPLE_RATE,
            dtype='int16',
            blocksize=FRAME_SIZE,
        )
        stream.start()
        print("ğŸ™ å½•éŸ³å¼€å§‹")

        # å¯åŠ¨è¯è¯­æ£€æµ‹ä»»åŠ¡
        detector_task = asyncio.create_task(utterance_detector())

        try:
            async for msg in ws:
                if isinstance(msg, str):
                    current_utterance += msg
                    last_text_time = time.time()
                    print(f"â± æ”¶åˆ° ASR æ–‡æœ¬: {msg}")
                else:
                    print("âš ï¸ éæ–‡æœ¬æ¶ˆæ¯å¿½ç•¥")
        except Exception as e:
            print(f"â— WS é”™è¯¯: {e}")
        finally:
            detector_task.cancel()
            stream.stop()

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("é€€å‡ºå®¢æˆ·ç«¯")
