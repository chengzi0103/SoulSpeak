# import sounddevice as sd
# import websocket
# import threading
# import time
# import webrtcvad
#
# from soul_speak.utils.hydra_config.init import conf
#
# # WebSocket æœåŠ¡å™¨åœ°å€
# # WS_URL = "ws://10.100.1.111:8765"
# WS_URL = f"ws://{conf.asr.websocket.host}:{conf.asr.websocket.port}"
# # è®¾ç½® VAD å‚æ•°
# vad = webrtcvad.Vad(2)
# # frame_duration = 30  # æ¯å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
# frame_duration = conf.asr.send_audio.frame_duration  # æ¯å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
# frame_size = int(16000 * frame_duration / 1000 * 2)  # æ¯å¸§å­—èŠ‚æ•°ï¼ˆ16-bit å•å£°é“ï¼‰
#
#
# def audio_callback(indata, frames, time_info, status):
#     if status:
#         print("Error:", status)
#     frame = indata[:, 0].copy()
#     try:
#         if vad.is_speech(frame.tobytes(), 16000):
#             if ws is not None:
#                 ws.send(frame.tobytes(), opcode=websocket.ABNF.OPCODE_BINARY)
#             else:
#                 print("WebSocket å°šæœªè¿æ¥")
#     except webrtcvad.VadError as e:
#         print("VAD å¤„ç†é”™è¯¯:", e)
#
#
# def record_audio():
#     stream = sd.InputStream(callback=audio_callback, channels=1,
#                             samplerate=conf.asr.send_audio.samplerate, dtype='int16', blocksize=480)
#     stream.start()
#     print("å¼€å§‹å½•éŸ³... æŒ‰ Ctrl+C åœæ­¢")
#     try:
#         while True:
#             time.sleep(0.1)
#     except KeyboardInterrupt:
#         stream.stop()
#         print("å½•éŸ³åœæ­¢")
#
# def on_open(ws):
#     print("WebSocket è¿æ¥å·²å»ºç«‹")
#     threading.Thread(target=record_audio, daemon=True).start()
#
# def on_message(ws, message):
#     """æ¥æ”¶åˆ°æœåŠ¡å™¨æ¶ˆæ¯æ—¶çš„å›è°ƒå‡½æ•°"""
#     print("æ”¶åˆ°æœåŠ¡å™¨æ¶ˆæ¯:", message)
#
# def on_error(ws, error):
#     """WebSocket é”™è¯¯æ—¶çš„å›è°ƒå‡½æ•°"""
#     print("WebSocket é”™è¯¯:", error)
#
# def on_close(ws, close_status_code, close_msg):
#     """WebSocket è¿æ¥å…³é—­æ—¶çš„å›è°ƒå‡½æ•°"""
#     print("WebSocket è¿æ¥å·²å…³é—­")
#
# if __name__ == "__main__":
#     global ws
#     ws = websocket.WebSocketApp(WS_URL,
#                                 on_open=on_open,
#                                 on_message=on_message,
#                                 on_error=on_error,
#                                 on_close=on_close)
#     ws.run_forever()
import asyncio
import sounddevice as sd
import webrtcvad
import collections
import time
import websockets

from soul_speak.llm.run_and_speak import tts_pipeline
from soul_speak.utils.hydra_config.init import conf

# --- é…ç½® ---
WS_URL = f"ws://{conf.asr.websocket.host}:{conf.asr.websocket.port}"
SAMPLE_RATE = conf.asr.send_audio.samplerate
FRAME_DURATION_MS = conf.asr.send_audio.frame_duration
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION_MS / 1000)
VAD_MODE = 2
VAD_SILENCE_TIMEOUT = conf.asr.send_audio.vad_silence_timeout
MIN_CHAR_COUNT = 3  # æœ€å°‘å­—ç¬¦æ•°

# --- å…¨å±€çŠ¶æ€ ---
vad = webrtcvad.Vad(VAD_MODE)
ring_buffer = collections.deque(maxlen=int(300 / FRAME_DURATION_MS))
triggered = False
speech_buffer = bytearray()
silence_start = None

current_utterance = ""
last_text_time = time.time()
processing = False
loop = None
global_ws = None

# --- å‘é€éŸ³é¢‘æ®µ ---
async def send_audio_segment(ws):
    global speech_buffer
    if speech_buffer:
        await ws.send(speech_buffer)
        speech_buffer = bytearray()
    await ws.send("$$END$$")

# --- éŸ³é¢‘å›è°ƒ ---
def audio_callback(indata, frames, time_info, status):
    global triggered, ring_buffer, speech_buffer, silence_start, loop, global_ws
    pcm = indata[:, 0].tobytes()
    is_speech = vad.is_speech(pcm, SAMPLE_RATE)

    if not triggered:
        ring_buffer.append(pcm)
        if sum(vad.is_speech(f, SAMPLE_RATE) for f in ring_buffer) > 0.9 * ring_buffer.maxlen:
            triggered = True
            speech_buffer.extend(b"".join(ring_buffer))
            ring_buffer.clear()
    else:
        speech_buffer.extend(pcm)
        if not is_speech:
            if silence_start is None:
                silence_start = time.time()
            elif time.time() - silence_start > VAD_SILENCE_TIMEOUT:
                # è§¦å‘å‘é€
                if loop and global_ws:
                    asyncio.run_coroutine_threadsafe(
                        send_audio_segment(global_ws), loop)
                triggered = False
                silence_start = None
        else:
            silence_start = None

# --- ç”¨æˆ·è¯è¯­æ£€æµ‹ ---
async def utterance_detector():
    global current_utterance, last_text_time, processing
    while True:
        await asyncio.sleep(0.5)
        if (current_utterance.strip() and
            time.time() - last_text_time > VAD_SILENCE_TIMEOUT and
            not processing and
            len(current_utterance.strip()) >= MIN_CHAR_COUNT):

            processing = True
            text = current_utterance.strip()
            current_utterance = ""
            print(f"ğŸ“£ ç”¨æˆ·è¯è¯­å®Œæˆ: {text}")
            try:
                await tts_pipeline("""This is the content of the user's voice. Since it is recognized by ASR, there may be text errors. Please analyze the user's input.  : """ + text)
            except Exception as e:
                print(f"â— TTS å¤±è´¥: {e}")
            processing = False

# --- ä¸»æµç¨‹ ---
async def main():
    global loop, global_ws, current_utterance, last_text_time, processing
    loop = asyncio.get_running_loop()

    print(f"è¿æ¥ ASR æœåŠ¡: {WS_URL}")
    async with websockets.connect(WS_URL) as ws:
        global_ws = ws
        # å¯åŠ¨å½•éŸ³
        stream = sd.InputStream(callback=audio_callback,
                                channels=1, samplerate=SAMPLE_RATE,
                                dtype='int16', blocksize=FRAME_SIZE,)
        sd.default.device = (1, 2)
        stream.start()
        print("ğŸ™ å½•éŸ³å¼€å§‹")

        # å¯åŠ¨è¯è¯­æ£€æµ‹ä»»åŠ¡
        detector_task = asyncio.create_task(utterance_detector())

        try:
            async for msg in ws:
                if isinstance(msg, str):
                    # å£°æ˜å…¨å±€å˜é‡
                    global current_utterance, last_text_time
                    current_utterance += msg
                    last_text_time = time.time()
                    print(f"â± æ”¶åˆ° ASR æ–‡æœ¬: {msg}")
                else:
                    print("âš ï¸ éæ–‡æœ¬æ¶ˆæ¯å¿½ç•¥")
        except Exception as e:
            print(f"â— WS é”™è¯¯: {e}")
        finally:
            detector_task.cancel()
            stream.stop()

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("é€€å‡ºå®¢æˆ·ç«¯")
